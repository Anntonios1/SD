# Arquitectura del Sistema - Sistema Distribuido GPU

## ğŸ¯ VisiÃ³n General

Este sistema implementa una arquitectura distribuida para procesamiento de jobs que requieren GPU, con capacidad de escalamiento horizontal y balanceo de carga.

## ğŸ“ Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cliente   â”‚ (EnvÃ­a jobs)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RabbitMQ Broker   â”‚ (Cola de mensajes)
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ job_queue   â”‚   â”‚
â”‚   â”‚ gpu_queue   â”‚   â”‚
â”‚   â”‚ cpu_queue   â”‚   â”‚
â”‚   â”‚result_queue â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scheduler  â”‚ (Distribuye jobs)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼                 â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GPU Worker  â”‚   â”‚ GPU Worker  â”‚ â”‚ CPU Worker  â”‚
â”‚   (Node 1)  â”‚   â”‚   (Node 2)  â”‚ â”‚   (Node 3)  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Resultados â”‚
         â”‚   Monitor   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ§© Componentes

### 1. Cliente (Client)
**Responsabilidad:** Enviar jobs al sistema

**Archivos:**
- `client/submit_job.py`: CLI para enviar jobs
- `client/results_monitor.py`: Monitor de resultados

**Funciones:**
- Crear jobs con parÃ¡metros especÃ­ficos
- Especificar preferencia GPU/CPU
- Enviar jobs a la cola principal

### 2. Broker (RabbitMQ)
**Responsabilidad:** GestiÃ³n de colas de mensajes

**Colas:**
- `job_queue`: Cola principal de entrada
- `gpu_queue`: Cola para workers GPU
- `cpu_queue`: Cola para workers CPU
- `result_queue`: Cola de resultados

**CaracterÃ­sticas:**
- Mensajes persistentes
- Acknowledgments
- Reintento automÃ¡tico en fallos

### 3. Scheduler
**Responsabilidad:** Distribuir jobs a workers apropiados

**Archivos:**
- `scheduler/scheduler.py`

**Estrategia:**
1. Recibe job de `job_queue`
2. EvalÃºa preferencia GPU/CPU
3. Enruta a cola apropiada
4. Registra asignaciÃ³n

**Mejoras futuras:**
- Balanceo de carga dinÃ¡mico
- PriorizaciÃ³n de jobs
- EstimaciÃ³n de tiempo de ejecuciÃ³n

### 4. Workers

#### GPU Worker
**Responsabilidad:** Ejecutar jobs con aceleraciÃ³n GPU

**Archivos:**
- `workers/gpu_worker.py`
- `workers/jobs/job_executor.py`

**CaracterÃ­sticas:**
- Detecta GPU automÃ¡ticamente
- Usa PyTorch con CUDA
- SincronizaciÃ³n CUDA para timing preciso
- Manejo de errores robusto

**Jobs Soportados:**
- Matrix Multiplication
- Neural Network Training
- Vector Addition
- Image Processing

#### CPU Worker
**Responsabilidad:** Ejecutar jobs en CPU (comparaciÃ³n)

**Archivos:**
- `workers/cpu_worker.py`
- `workers/jobs/job_executor.py`

**CaracterÃ­sticas:**
- Mismo cÃ³digo que GPU worker
- Usa CPU para ejecuciÃ³n
- Permite comparaciÃ³n de performance

### 5. Job Executor
**Responsabilidad:** ImplementaciÃ³n de tipos de jobs

**Archivos:**
- `workers/jobs/job_executor.py`

**Job Types:**

#### Matrix Multiplication
```python
{
    'job_type': 'matrix_multiply',
    'size': 1000,
    'iterations': 10
}
```
- Multiplica matrices NxN
- Benchmark de FLOPS
- Ideal para GPU

#### Neural Network Training
```python
{
    'job_type': 'neural_network',
    'epochs': 5,
    'batch_size': 64,
    'input_size': 784,
    'hidden_size': 256,
    'output_size': 10
}
```
- Red neuronal simple (2 capas)
- Forward + backward pass
- OptimizaciÃ³n con Adam

#### Vector Addition
```python
{
    'job_type': 'vector_addition',
    'size': 10000000,
    'iterations': 100
}
```
- OperaciÃ³n elemento a elemento
- Benchmark de bandwidth de memoria
- Overhead de transferencia GPU

#### Image Processing
```python
{
    'job_type': 'image_processing',
    'batch_size': 32,
    'image_size': 224,
    'iterations': 50
}
```
- Convoluciones 2D
- Similar a CNNs
- Operaciones intensivas en GPU

## ğŸ”„ Flujo de Datos

### 1. EnvÃ­o de Job
```
Cliente â†’ job_queue â†’ Scheduler
```

1. Cliente crea job con parÃ¡metros
2. Job se serializa a JSON
3. Se publica en `job_queue`
4. Mensaje se marca como persistente

### 2. Scheduling
```
Scheduler â†’ gpu_queue/cpu_queue
```

1. Scheduler consume de `job_queue`
2. EvalÃºa `prefer_gpu` flag
3. Enruta a cola apropiada
4. Confirma recepciÃ³n (ACK)

### 3. EjecuciÃ³n
```
Worker â†’ Procesamiento â†’ result_queue
```

1. Worker consume de su cola
2. Ejecuta job con JobExecutor
3. Mide tiempos de ejecuciÃ³n
4. Publica resultado con metadata
5. Confirma procesamiento (ACK)

### 4. Resultados
```
result_queue â†’ Monitor â†’ Archivo
```

1. Monitor consume resultados
2. Calcula estadÃ­sticas
3. Guarda a archivo JSON
4. Actualiza mÃ©tricas en tiempo real

## ğŸ³ Arquitectura Docker

### Redes
- `gpu-cluster`: Red bridge para comunicaciÃ³n entre contenedores

### VolÃºmenes
- `rabbitmq_data`: Persistencia de RabbitMQ
- `./results`: Resultados compartidos con host

### Servicios

```yaml
rabbitmq:
  - Puerto 5672: AMQP
  - Puerto 15672: Management UI
  
scheduler:
  - Depende de: rabbitmq
  
gpu-worker:
  - Depende de: rabbitmq, scheduler
  - Requiere: nvidia runtime
  - GPU: 1
  
cpu-worker:
  - Depende de: rabbitmq, scheduler
  - CPU: 2 cores
  - RAM: 4GB
  
metrics:
  - Puerto 8000: API
  - Volumen: ./results
```

## â˜¸ï¸ Arquitectura Kubernetes

### Namespace
- `gpu-cluster`: Aislamiento de recursos

### Deployments

#### RabbitMQ
- Replicas: 1
- Storage: EmptyDir (demo) o PVC (producciÃ³n)
- Service: ClusterIP

#### Scheduler
- Replicas: 1
- Depends: RabbitMQ ready

#### GPU Workers
- Replicas: 1+ (segÃºn GPUs disponibles)
- Node Selector: `accelerator=nvidia-gpu`
- Tolerations: `nvidia.com/gpu:NoSchedule`
- Resources: `nvidia.com/gpu: 1`

#### CPU Workers
- Replicas: 2+
- Resources: 2 CPU, 4GB RAM

#### Metrics Monitor
- Replicas: 1
- PVC: 1GB para resultados
- Service: LoadBalancer (puerto 8000)

### Recursos

```yaml
GPU Worker:
  resources:
    limits:
      nvidia.com/gpu: 1
    requests:
      nvidia.com/gpu: 1

CPU Worker:
  resources:
    limits:
      cpu: "2"
      memory: "4Gi"
    requests:
      cpu: "1"
      memory: "2Gi"
```

## ğŸ” ConfiguraciÃ³n

### Variables de Entorno

```bash
# RabbitMQ
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_USER=admin
RABBITMQ_PASS=admin123

# Worker
WORKER_TYPE=gpu|cpu
WORKER_ID=worker-xxx
```

### Colas RabbitMQ

```python
# ConfiguraciÃ³n
durable=True           # Persistencia de cola
delivery_mode=2        # Mensajes persistentes
prefetch_count=1       # Un job por worker
acknowledgment=True    # ConfirmaciÃ³n manual
```

## ğŸ“Š MÃ©tricas y Monitoreo

### MÃ©tricas por Job
- `job_id`: Identificador Ãºnico
- `job_type`: Tipo de trabajo
- `worker_id`: Worker que procesÃ³
- `worker_type`: GPU o CPU
- `processing_time`: Tiempo total
- `device`: Dispositivo usado
- `status`: completed/failed

### MÃ©tricas Agregadas
- Count por job_type y worker_type
- Avg, min, max processing time
- Speedup GPU vs CPU
- Throughput (jobs/segundo)

### VisualizaciÃ³n
- GrÃ¡ficas comparativas
- Tablas de resultados
- Reporte en Markdown
- ExportaciÃ³n CSV

## ğŸš€ Escalabilidad

### Horizontal
- MÃºltiples GPU workers (1 GPU cada uno)
- MÃºltiples CPU workers
- RabbitMQ cluster (producciÃ³n)

### Vertical
- Workers con mÃºltiples GPUs
- Batch processing de jobs
- ParalelizaciÃ³n interna

### Limitaciones
- RabbitMQ single instance (demo)
- Sin load balancing avanzado
- Sin failover automÃ¡tico

## ğŸ”§ Extensibilidad

### Agregar Nuevo Job Type

1. AÃ±adir mÃ©todo en `JobExecutor`:
```python
def new_job_type(self, job_data):
    # ImplementaciÃ³n
    return result
```

2. Registrar en `execute()`:
```python
elif job_type == 'new_job_type':
    return self.new_job_type(job_data)
```

3. AÃ±adir helper en `JobClient`:
```python
def submit_new_job(self, params):
    return self.submit_job('new_job_type', params)
```

### Agregar Nueva Estrategia de Scheduling

1. Modificar `scheduler.py`:
```python
def advanced_schedule(self, job_data):
    # EvaluaciÃ³n de carga
    # EstimaciÃ³n de tiempo
    # SelecciÃ³n de worker Ã³ptimo
```

## ğŸ“ Casos de Uso

### 1. Machine Learning Training
- Dataset grande
- MÃºltiples Ã©pocas
- GPU acelera entrenamiento

### 2. ComputaciÃ³n CientÃ­fica
- Simulaciones numÃ©ricas
- Ãlgebra lineal
- Procesamiento paralelo

### 3. Procesamiento de ImÃ¡genes
- Batch de imÃ¡genes
- Filtros y transformaciones
- CNNs para anÃ¡lisis

### 4. AnÃ¡lisis de Datos
- Operaciones matriciales
- Agregaciones masivas
- GPU para big data

## ğŸ“š Referencias

- [RabbitMQ Tutorials](https://www.rabbitmq.com/getstarted.html)
- [PyTorch CUDA Semantics](https://pytorch.org/docs/stable/notes/cuda.html)
- [Kubernetes GPU Support](https://kubernetes.io/docs/tasks/manage-gpus/scheduling-gpus/)
- [Docker GPU Support](https://docs.docker.com/config/containers/resource_constraints/#gpu)

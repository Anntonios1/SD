# FAQ - Preguntas Frecuentes

## ğŸ¤” Preguntas Generales

### Â¿QuÃ© es este proyecto?
Un sistema distribuido que ejecuta jobs computacionales en GPU y CPU, comparando performance y gestionando colas de trabajos con RabbitMQ.

### Â¿Para quÃ© sirve?
- Demostrar aceleraciÃ³n GPU vs CPU
- Aprender sistemas distribuidos
- OrquestaciÃ³n de trabajos computacionales
- Proyecto final de Sistemas Distribuidos

### Â¿Necesito una GPU fÃ­sica?
No es obligatorio. El sistema funciona en modo CPU-only para testing. Los speedups serÃ¡n menores pero el sistema es completamente funcional.

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Â¿CÃ³mo instalo las dependencias?

```powershell
# 1. Crear entorno virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Para GPU (opcional)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Â¿CÃ³mo verifico que tengo GPU disponible?

```powershell
# Test 1: NVIDIA SMI
nvidia-smi

# Test 2: PyTorch
python -c "import torch; print(torch.cuda.is_available())"

# Test 3: Script de verificaciÃ³n
python test_system.py
```

### Â¿QuÃ© hacer si no tengo GPU?

El sistema funciona perfectamente sin GPU:
- Los workers GPU se ejecutarÃ¡n en CPU
- PodrÃ¡s comparar workers optimizados vs no optimizados
- Los speedups serÃ¡n menores pero funcional

## ğŸ³ Docker

### Â¿CÃ³mo inicio el sistema con Docker?

```powershell
# Iniciar
docker-compose up -d

# Ver logs
docker-compose logs -f

# Detener
docker-compose down
```

### Â¿CÃ³mo verifico que los contenedores estÃ¡n corriendo?

```powershell
docker-compose ps
```

DeberÃ­as ver:
- `rabbitmq-broker` - Up
- `job-scheduler` - Up
- `gpu-worker-1` - Up
- `cpu-worker-1` - Up
- `metrics-collector` - Up

### Â¿CÃ³mo accedo al RabbitMQ Dashboard?

```
URL: http://localhost:15672
Usuario: admin
Password: admin123
```

### Error: "no configuration file provided"

```powershell
# AsegÃºrate de estar en el directorio raÃ­z del proyecto
cd "C:\Users\teamp\Documents\Proyecto final"
docker-compose up -d
```

### Error: "Cannot connect to the Docker daemon"

```powershell
# Iniciar Docker Desktop
# O desde servicios:
Start-Service docker
```

### Error: "nvidia runtime not found"

Si no tienes GPU, modifica `docker-compose.yml`:

```yaml
# Comentar estas lÃ­neas en gpu-worker:
# runtime: nvidia
# deploy:
#   resources:
#     reservations:
#       devices:
#         - driver: nvidia
#           count: 1
#           capabilities: [gpu]
```

## ğŸ“¤ Enviar Jobs

### Â¿CÃ³mo envÃ­o mi primer job?

```powershell
python client/submit_job.py --job-type matrix-multiply --size 500
```

### Â¿QuÃ© tipos de jobs puedo enviar?

1. `matrix-multiply` - MultiplicaciÃ³n de matrices
2. `neural-network` - Entrenamiento de red neuronal
3. `vector-add` - Suma de vectores
4. `image-processing` - Procesamiento de imÃ¡genes

### Â¿CÃ³mo especifico GPU o CPU?

```powershell
# GPU (default)
python client/submit_job.py --job-type matrix-multiply --size 1000

# CPU
python client/submit_job.py --job-type matrix-multiply --size 1000 --cpu
```

### Â¿CÃ³mo envÃ­o mÃºltiples jobs?

```powershell
python client/submit_job.py --job-type matrix-multiply --size 1000 --count 10
```

### Â¿DÃ³nde veo los resultados?

```powershell
# Monitor en tiempo real
python client/results_monitor.py

# Archivo de resultados
cat results/job_results.json
```

## ğŸ“Š Benchmarks y Resultados

### Â¿CÃ³mo ejecuto los benchmarks?

```powershell
# 1. Iniciar monitor (Terminal 1)
python client/results_monitor.py

# 2. Ejecutar benchmarks (Terminal 2)
python benchmarks/run_benchmarks.py

# 3. Esperar a que completen (5-10 min)

# 4. Analizar
python benchmarks/analyze_results.py
```

### Â¿CuÃ¡nto tiempo toman los benchmarks?

- **Quick mode**: 2-3 minutos
- **Full suite**: 10-15 minutos
- Depende de tu hardware

### Â¿DÃ³nde estÃ¡n los resultados?

```
results/
â”œâ”€â”€ job_results.json              # Datos crudos
â”œâ”€â”€ performance_comparison.csv    # Tabla comparativa
â”œâ”€â”€ performance_comparison.png    # GrÃ¡ficos
â””â”€â”€ BENCHMARK_REPORT.md           # Reporte
```

### Â¿QuÃ© speedups son normales?

Depende del hardware, pero tÃ­picamente:
- Matrix Multiply: 30-100x
- Neural Network: 20-50x
- Image Processing: 25-60x
- Vector Addition: 5-15x

## â˜¸ï¸ Kubernetes

### Â¿CÃ³mo despliego en Kubernetes?

```powershell
# 1. Construir imÃ¡genes
.\scripts\build_images.ps1

# 2. Cargar en Minikube (si usas Minikube)
minikube image load gpu-cluster/scheduler:latest
# ... repetir para todas las imÃ¡genes

# 3. Desplegar
.\scripts\deploy_k8s.ps1

# 4. Verificar
kubectl get pods -n gpu-cluster
```

### Â¿CÃ³mo etiquetar nodos GPU?

```bash
# Listar nodos
kubectl get nodes

# Etiquetar nodo con GPU
kubectl label nodes <node-name> accelerator=nvidia-gpu

# Verificar
kubectl get nodes --show-labels | grep gpu
```

### Â¿CÃ³mo escalar workers?

```bash
# Escalar GPU workers
kubectl scale deployment gpu-worker --replicas=2 -n gpu-cluster

# Escalar CPU workers
kubectl scale deployment cpu-worker --replicas=4 -n gpu-cluster
```

### Â¿CÃ³mo ver logs en Kubernetes?

```bash
# Logs de scheduler
kubectl logs -f deployment/scheduler -n gpu-cluster

# Logs de GPU worker
kubectl logs -f deployment/gpu-worker -n gpu-cluster

# Todos los logs
kubectl logs -f -l app=gpu-worker -n gpu-cluster --all-containers
```

## ğŸ› Troubleshooting

### Workers no procesan jobs

```powershell
# Verificar que RabbitMQ estÃ¡ corriendo
docker-compose ps rabbitmq

# Reiniciar workers
docker-compose restart gpu-worker cpu-worker

# Ver logs
docker-compose logs -f gpu-worker
```

### "Connection refused" al conectar a RabbitMQ

```powershell
# Esperar 30 segundos despuÃ©s de iniciar
Start-Sleep -Seconds 30

# Verificar que el puerto estÃ¡ abierto
Test-NetConnection -ComputerName localhost -Port 5672

# Reiniciar RabbitMQ
docker-compose restart rabbitmq
```

### Jobs se quedan en la cola sin procesarse

1. Verificar que hay workers corriendo:
   ```powershell
   docker-compose ps
   ```

2. Verificar que el scheduler estÃ¡ corriendo:
   ```powershell
   docker-compose logs scheduler
   ```

3. Verificar colas en RabbitMQ:
   - Ir a http://localhost:15672
   - Ver pestaÃ±a "Queues"
   - Verificar consumers activos

### "CUDA out of memory"

```powershell
# Reducir tamaÃ±o de jobs
python client/submit_job.py --job-type matrix-multiply --size 500

# O reducir batch size
python client/submit_job.py --job-type neural-network --batch-size 32
```

### ImportaciÃ³n de mÃ³dulos falla

```powershell
# Asegurarte de estar en el directorio raÃ­z
cd "C:\Users\teamp\Documents\Proyecto final"

# Verificar que el mÃ³dulo existe
ls workers/jobs/job_executor.py

# Ejecutar desde raÃ­z
python client/submit_job.py
```

## ğŸ“ Informe IEEE

### Â¿QuÃ© debe incluir el informe?

Ver la guÃ­a completa en `docs/IEEE_REPORT_GUIDE.md`

Secciones principales:
1. Abstract
2. Introduction
3. Architecture
4. Implementation
5. Experimental Results
6. Analysis
7. Conclusions

### Â¿QuÃ© figuras incluir?

MÃ­nimo:
1. Diagrama de arquitectura
2. GrÃ¡fico GPU vs CPU
3. Tabla de resultados
4. Diagrama de flujo
5. Screenshots del sistema

### Â¿CÃ³mo genero los resultados para el informe?

```powershell
# 1. Ejecutar benchmarks
python benchmarks/run_benchmarks.py

# 2. Analizar
python benchmarks/analyze_results.py

# 3. Copiar archivos
mkdir informe
cp results/performance_comparison.* informe/
cp results/BENCHMARK_REPORT.md informe/
```

## ğŸ¯ Performance

### Â¿CÃ³mo mejoro el rendimiento?

1. **Usar tamaÃ±os grandes**: Jobs >1000 aprovechan mejor GPU
2. **Batch jobs**: Enviar mÃºltiples jobs a la vez
3. **Ajustar parÃ¡metros**: Experimentar con diferentes configs
4. **Monitorear GPU**: Usar nvidia-smi para ver utilizaciÃ³n

### Â¿Por quÃ© algunos jobs son lentos en GPU?

- **Overhead de transferencia**: Jobs muy pequeÃ±os
- **No paralelizable**: Algunos algoritmos no se benefician
- **Memory bound**: Limitado por bandwidth de memoria

### Â¿CÃ³mo monitoreo utilizaciÃ³n de GPU?

```powershell
# Consola interactiva
nvidia-smi -l 1

# Guardar a archivo
nvidia-smi --query-gpu=utilization.gpu,utilization.memory --format=csv --loop=1 > gpu_usage.csv
```

## ğŸ”§ Desarrollo

### Â¿CÃ³mo agrego un nuevo tipo de job?

Ver guÃ­a completa en `docs/EXTENDING.md`

Pasos bÃ¡sicos:
1. Agregar mÃ©todo en `JobExecutor`
2. Registrar en `execute()`
3. Agregar helper en `JobClient`
4. Actualizar CLI

### Â¿CÃ³mo modifico el scheduler?

Editar `scheduler/scheduler.py`:
- Implementar nueva estrategia de scheduling
- Agregar prioridades
- Load balancing
- SLA awareness

### Â¿CÃ³mo agrego nuevas mÃ©tricas?

1. Modificar worker para recopilar mÃ©trica
2. Incluir en resultado del job
3. Actualizar monitor para procesar
4. Actualizar anÃ¡lisis para visualizar

## ğŸ“ Para el Proyecto Final

### Â¿Es suficiente para aprobar?

SÃ­. El proyecto incluye:
- âœ… Sistema distribuido funcional
- âœ… Workers GPU/CPU
- âœ… Cola de mensajes (RabbitMQ)
- âœ… Scheduler
- âœ… ContainerizaciÃ³n (Docker)
- âœ… OrquestaciÃ³n (Kubernetes)
- âœ… Benchmarks y mÃ©tricas
- âœ… DocumentaciÃ³n completa

### Â¿QuÃ© mostrar en la demo?

1. **Arquitectura**: Explicar componentes
2. **Despliegue**: Mostrar Docker/K8s
3. **EjecuciÃ³n**: Enviar jobs en vivo
4. **Resultados**: Mostrar comparaciÃ³n GPU vs CPU
5. **MÃ©tricas**: Dashboard de RabbitMQ
6. **CÃ³digo**: Mostrar implementaciÃ³n clave

### Â¿QuÃ© hacer si no funciona en la demo?

1. **Tener video backup**: Grabar demo funcionando
2. **Screenshots**: Capturar todo con anticipaciÃ³n
3. **Logs guardados**: Tener logs de ejecuciÃ³n exitosa
4. **Resultados pre-generados**: Tener benchmarks ya ejecutados

## ğŸ’¡ Tips Finales

### Antes de la entrega

```powershell
# Test completo del sistema
python test_system.py

# Ejecutar demo completo
.\scripts\run_demo.ps1

# Generar todos los resultados
python benchmarks/run_benchmarks.py
python benchmarks/analyze_results.py

# Verificar documentaciÃ³n
ls docs/
ls results/
```

### Para la presentaciÃ³n

1. Practicar demo varias veces
2. Tener terminal lista con comandos
3. Abrir RabbitMQ dashboard
4. Tener grÃ¡ficos visibles
5. Preparar explicaciÃ³n de arquitectura

### Recursos Ãºtiles

- `QUICKSTART.md` - Inicio rÃ¡pido
- `PROJECT_STATUS.md` - Estado completo
- `docs/USER_GUIDE.md` - GuÃ­a detallada
- `docs/DEPLOYMENT_GUIDE.md` - Troubleshooting

## â“ Â¿MÃ¡s preguntas?

Revisa la documentaciÃ³n en la carpeta `docs/` o los archivos:
- README.md
- QUICKSTART.md
- PROJECT_STATUS.md
- docs/USER_GUIDE.md
- docs/DEPLOYMENT_GUIDE.md
- docs/ARCHITECTURE.md
- docs/IEEE_REPORT_GUIDE.md
- docs/EXTENDING.md
